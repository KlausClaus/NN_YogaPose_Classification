{
 "cells": [
  {
   "cell_type": "code",
   "id": "7d0bf75bd5d9cf81",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-12T16:39:03.749682Z",
     "start_time": "2024-11-12T16:39:03.732817Z"
    }
   },
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image, ImageFile\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import requests\n",
    "import sys"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T16:39:03.765519Z",
     "start_time": "2024-11-12T16:39:03.750679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Model imports\n",
    "from keras import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "# Download helper functions\n",
    "url = \"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\"\n",
    "file_path = \"helper_functions.py\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    response = requests.get(url)\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download complete!\")\n",
    "else:\n",
    "    print(\"helper_functions.py already exists locally. Skipping download.\")\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "from helper_functions import create_tensorboard_callback"
   ],
   "id": "87eb8d9eb7cb11",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T16:39:04.250712Z",
     "start_time": "2024-11-12T16:39:03.766515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Data Generator setup - with augmentation\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=0.2,\n",
    "    rescale=1. / 255\n",
    ")\n",
    "\n",
    "# Load data\n",
    "root_path = r'C:\\Users\\Anderson\\Documents\\GitHub\\COMP9444_project\\Dataset\\Yoga-82\\yoga_dataset_links_skeleton'  # Update with your path\n",
    "train_ds = data_gen.flow_from_directory(\n",
    "    root_path,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "valid_ds = data_gen.flow_from_directory(\n",
    "    root_path,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Get number of classes\n",
    "n_classes = len(train_ds.class_indices)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"适用于长期训练的学习率调度策略\"\"\"\n",
    "    initial_lr = 0.001\n",
    "\n",
    "    if epoch < 5:\n",
    "        return initial_lr\n",
    "    elif epoch < 15:\n",
    "        return initial_lr * 0.5\n",
    "    elif epoch < 30:\n",
    "        return initial_lr * 0.1\n",
    "    elif epoch < 50:\n",
    "        return initial_lr * 0.05\n",
    "    elif epoch < 70:\n",
    "        return initial_lr * 0.01\n",
    "    else:\n",
    "        return initial_lr * 0.005"
   ],
   "id": "65999a05b25bf9fc",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T16:39:04.282118Z",
     "start_time": "2024-11-12T16:39:04.252811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def build_model(trainable=False, learning_rate=0.001):\n",
    "    \"\"\"构建模型\"\"\"\n",
    "    base_model = Xception(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(256, 256, 3)\n",
    "    )\n",
    "\n",
    "    # 设置基础模型是否可训练\n",
    "    base_model.trainable = trainable\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"两阶段训练模型，支持更长时间的训练\"\"\"\n",
    "    # 第一阶段：训练顶层分类器\n",
    "    print(\"Stage 1: Training top layers...\")\n",
    "    model = build_model(trainable=False, learning_rate=0.001)\n",
    "\n",
    "    callbacks_stage1 = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=7,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            'yoga_pose_model_stage1.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        create_tensorboard_callback(\"training_logs\", \"yoga_classification_stage1\")\n",
    "    ]\n",
    "\n",
    "    history1 = model.fit(\n",
    "        train_ds,\n",
    "        epochs=30,\n",
    "        validation_data=valid_ds,\n",
    "        callbacks=callbacks_stage1\n",
    "    )\n",
    "\n",
    "    # 第二阶段：微调整个模型\n",
    "    print(\"\\nStage 2: Fine-tuning the entire model...\")\n",
    "    model = build_model(trainable=True, learning_rate=0.0001)\n",
    "\n",
    "    # 解冻后几层进行微调\n",
    "    for layer in model.layers[0].layers[:-20]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    callbacks_stage2 = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=15,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            'yoga_pose_model_stage2.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=7,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        LearningRateScheduler(lr_schedule, verbose=1),\n",
    "        create_tensorboard_callback(\"training_logs\", \"yoga_classification_stage2\")\n",
    "    ]\n",
    "\n",
    "    history2 = model.fit(\n",
    "        train_ds,\n",
    "        epochs=70,\n",
    "        validation_data=valid_ds,\n",
    "        callbacks=callbacks_stage2\n",
    "    )\n",
    "\n",
    "    return model, history1, history2\n",
    "\n",
    "def plot_training_history(history1, history2):\n",
    "    \"\"\"改进的训练历史可视化\"\"\"\n",
    "    # 合并两个阶段的历史\n",
    "    acc = history1.history['accuracy'] + history2.history['accuracy']\n",
    "    val_acc = history1.history['val_accuracy'] + history2.history['val_accuracy']\n",
    "    loss = history1.history['loss'] + history2.history['loss']\n",
    "    val_loss = history1.history['val_loss'] + history2.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # 准确率曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "    plt.axvline(x=len(history1.history['accuracy']), color='g', linestyle='--', label='Stage Change')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 损失曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    plt.axvline(x=len(history1.history['loss']), color='g', linestyle='--', label='Stage Change')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "    superimposed_img.save(cam_path)\n",
    "    return cam_path"
   ],
   "id": "524894d074ed4c07",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:23:54.579175Z",
     "start_time": "2024-11-12T16:39:04.283115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def evaluate_model(model, test_ds):\n",
    "    \"\"\"评估模型性能\"\"\"\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    \n",
    "    # 基本评估\n",
    "    test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)\n",
    "    print(\"    Test Loss: {:.5f}\".format(test_loss))\n",
    "    print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "    \n",
    "    # 预测\n",
    "    pred = model.predict(test_ds)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    \n",
    "    # 获取标签映射\n",
    "    labels = test_ds.class_indices\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    pred = [labels[k] for k in pred]\n",
    "    \n",
    "    # 显示前5个预测结果\n",
    "    print(f'The first 5 predictions: {pred[:5]}')\n",
    "    \n",
    "    # 显示随机样本的预测结果\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    random_indices = np.random.randint(0, len(test_ds.filepaths) - 1, 15)\n",
    "    \n",
    "    for i, idx in enumerate(random_indices):\n",
    "        plt.subplot(3, 5, i + 1)\n",
    "        img = plt.imread(test_ds.filepaths[idx])\n",
    "        plt.imshow(img)\n",
    "        true_label = labels[test_ds.classes[idx]]\n",
    "        pred_label = pred[idx]\n",
    "        color = \"green\" if true_label == pred_label else \"red\"\n",
    "        plt.title(f\"True: {true_label}\\nPredicted: {pred_label}\", color=color)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 分类报告\n",
    "    y_test = [labels[k] for k in test_ds.classes]\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, pred))\n",
    "    \n",
    "    # Grad-CAM 可视化\n",
    "    last_conv_layer_name = \"Conv_1\"  # For Xception model\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, idx in enumerate(random_indices[:15]):\n",
    "        img_path = test_ds.filepaths[idx]\n",
    "        img_array = tf.keras.applications.xception.preprocess_input(get_img_array(img_path, size=(256, 256)))\n",
    "        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "        cam_path = save_and_display_gradcam(img_path, heatmap)\n",
    "        plt.subplot(3, 5, i + 1)\n",
    "        plt.imshow(plt.imread(cam_path))\n",
    "        plt.title(f\"True: {y_test[idx]}\\nPredicted: {pred[idx]}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting training process...\")\n",
    "    print(f\"Number of classes: {n_classes}\")\n",
    "\n",
    "    # 训练模型\n",
    "    model, history1, history2 = train_model()\n",
    "\n",
    "    # 绘制训练历史\n",
    "    plot_training_history(history1, history2)\n",
    "\n",
    "    # 评估最终模型\n",
    "    final_loss, final_accuracy = evaluate_model(model, valid_ds)\n",
    "\n",
    "    # 保存最终模型\n",
    "    model_save_path = 'final/yoga_pose_model_final.h5'\n",
    "    model.save(model_save_path)\n",
    "    print(f\"\\nModel saved to {model_save_path}\")\n",
    "\n",
    "    # 打印训练总结\n",
    "    print(\"\\nTraining Summary:\")\n",
    "    print(f\"Total epochs trained: {len(history1.history['accuracy']) + len(history2.history['accuracy'])}\")\n",
    "    print(f\"Best validation accuracy: {max(history1.history['val_accuracy'] + history2.history['val_accuracy']) * 100:.2f}%\")\n",
    "    print(f\"Final validation accuracy: {final_accuracy * 100:.2f}%\")"
   ],
   "id": "initial_id",
   "execution_count": 6,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
