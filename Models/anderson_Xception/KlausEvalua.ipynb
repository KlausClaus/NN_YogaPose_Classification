{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yoga Pose Classification\n",
    "\n",
    "### 1.Introduction\n",
    "\n",
    "### 2.Motivation\n",
    "\n",
    "### 3.Problem Statement\n",
    "\n",
    "### 4.Data Sources：\n",
    "\n",
    "### 5.Dataset Description:\n",
    "\n",
    "### 6.Challenging Aspects:\n",
    "The Yoga-82 dataset presents several challenges:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: CNN + MobileNetV3\n",
    "\n",
    "#### 1.1 Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:03.624944Z",
     "start_time": "2024-11-16T06:29:00.909694Z"
    }
   },
   "source": [
    "# Import Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint,TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Model\n",
    "# from tensorflow.keras.layers import Rescaling, Normalization, RandomFlip, RandomRotation\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# 检查 GPU 是否可用\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Using GPU:\", tf.config.list_physical_devices('GPU')[0])\n",
    "else:\n",
    "    print(\"No GPU detected, using CPU instead.\")\n",
    "\n",
    "\n",
    "# System libraries\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Create Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:03.639961Z",
     "start_time": "2024-11-16T06:29:03.625941Z"
    }
   },
   "source": [
    "# 设置文件 URL\n",
    "url = \"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\"\n",
    "\n",
    "file_path = \"helper_functions.py\"\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Send a GET request to fetch the file content\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Write the content to the file\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    print(\"Download complete!\")\n",
    "else:\n",
    "    print(\"helper_functions.py already exists locally. Skipping download.\")\n",
    "\n",
    "# Add the current working directory to the Python path\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Import series of helper functions for our notebook\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists locally. Skipping download.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:03.671434Z",
     "start_time": "2024-11-16T06:29:03.640957Z"
    }
   },
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# Walk through each directory\n",
    "dataset = \"../yoga_dataset_links\"\n",
    "walk_through_dir(dataset)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 82 directories and 0 images in '../yoga_dataset_links'.\n",
      "There are 0 directories and 84 images in '../yoga_dataset_links\\Akarna_Dhanurasana'.\n",
      "There are 0 directories and 76 images in '../yoga_dataset_links\\Bharadvaja's_Twist_pose_or_Bharadvajasana_I_'.\n",
      "There are 0 directories and 372 images in '../yoga_dataset_links\\Boat_Pose_or_Paripurna_Navasana_'.\n",
      "There are 0 directories and 260 images in '../yoga_dataset_links\\Bound_Angle_Pose_or_Baddha_Konasana_'.\n",
      "There are 0 directories and 216 images in '../yoga_dataset_links\\Bow_Pose_or_Dhanurasana_'.\n",
      "There are 0 directories and 251 images in '../yoga_dataset_links\\Bridge_Pose_or_Setu_Bandha_Sarvangasana_'.\n",
      "There are 0 directories and 307 images in '../yoga_dataset_links\\Camel_Pose_or_Ustrasana_'.\n",
      "There are 0 directories and 404 images in '../yoga_dataset_links\\Cat_Cow_Pose_or_Marjaryasana_'.\n",
      "There are 0 directories and 302 images in '../yoga_dataset_links\\Chair_Pose_or_Utkatasana_'.\n",
      "There are 0 directories and 293 images in '../yoga_dataset_links\\Child_Pose_or_Balasana_'.\n",
      "There are 0 directories and 756 images in '../yoga_dataset_links\\Cobra_Pose_or_Bhujangasana_'.\n",
      "There are 0 directories and 145 images in '../yoga_dataset_links\\Cockerel_Pose'.\n",
      "There are 0 directories and 315 images in '../yoga_dataset_links\\Corpse_Pose_or_Savasana_'.\n",
      "There are 0 directories and 299 images in '../yoga_dataset_links\\Cow_Face_Pose_or_Gomukhasana_'.\n",
      "There are 0 directories and 301 images in '../yoga_dataset_links\\Crane_(Crow)_Pose_or_Bakasana_'.\n",
      "There are 0 directories and 45 images in '../yoga_dataset_links\\Dolphin_Plank_Pose_or_Makara_Adho_Mukha_Svanasana_'.\n",
      "There are 0 directories and 74 images in '../yoga_dataset_links\\Dolphin_Pose_or_Ardha_Pincha_Mayurasana_'.\n",
      "There are 0 directories and 288 images in '../yoga_dataset_links\\Downward-Facing_Dog_pose_or_Adho_Mukha_Svanasana_'.\n",
      "There are 0 directories and 279 images in '../yoga_dataset_links\\Eagle_Pose_or_Garudasana_'.\n",
      "There are 0 directories and 185 images in '../yoga_dataset_links\\Eight-Angle_Pose_or_Astavakrasana_'.\n",
      "There are 0 directories and 78 images in '../yoga_dataset_links\\Extended_Puppy_Pose_or_Uttana_Shishosana_'.\n",
      "There are 0 directories and 511 images in '../yoga_dataset_links\\Extended_Revolved_Side_Angle_Pose_or_Utthita_Parsvakonasana_'.\n",
      "There are 0 directories and 497 images in '../yoga_dataset_links\\Extended_Revolved_Triangle_Pose_or_Utthita_Trikonasana_'.\n",
      "There are 0 directories and 208 images in '../yoga_dataset_links\\Feathered_Peacock_Pose_or_Pincha_Mayurasana_'.\n",
      "There are 0 directories and 183 images in '../yoga_dataset_links\\Firefly_Pose_or_Tittibhasana_'.\n",
      "There are 0 directories and 288 images in '../yoga_dataset_links\\Fish_Pose_or_Matsyasana_'.\n",
      "There are 0 directories and 214 images in '../yoga_dataset_links\\Four-Limbed_Staff_Pose_or_Chaturanga_Dandasana_'.\n",
      "There are 0 directories and 151 images in '../yoga_dataset_links\\Frog_Pose_or_Bhekasana'.\n",
      "There are 0 directories and 226 images in '../yoga_dataset_links\\Garland_Pose_or_Malasana_'.\n",
      "There are 0 directories and 158 images in '../yoga_dataset_links\\Gate_Pose_or_Parighasana_'.\n",
      "There are 0 directories and 290 images in '../yoga_dataset_links\\Half_Lord_of_the_Fishes_Pose_or_Ardha_Matsyendrasana_'.\n",
      "There are 0 directories and 262 images in '../yoga_dataset_links\\Half_Moon_Pose_or_Ardha_Chandrasana_'.\n",
      "There are 0 directories and 180 images in '../yoga_dataset_links\\Handstand_pose_or_Adho_Mukha_Vrksasana_'.\n",
      "There are 0 directories and 158 images in '../yoga_dataset_links\\Happy_Baby_Pose_or_Ananda_Balasana_'.\n",
      "There are 0 directories and 177 images in '../yoga_dataset_links\\Head-to-Knee_Forward_Bend_pose_or_Janu_Sirsasana_'.\n",
      "There are 0 directories and 136 images in '../yoga_dataset_links\\Heron_Pose_or_Krounchasana_'.\n",
      "There are 0 directories and 182 images in '../yoga_dataset_links\\Intense_Side_Stretch_Pose_or_Parsvottanasana_'.\n",
      "There are 0 directories and 219 images in '../yoga_dataset_links\\Legs-Up-the-Wall_Pose_or_Viparita_Karani_'.\n",
      "There are 0 directories and 217 images in '../yoga_dataset_links\\Locust_Pose_or_Salabhasana_'.\n",
      "There are 0 directories and 380 images in '../yoga_dataset_links\\Lord_of_the_Dance_Pose_or_Natarajasana_'.\n",
      "There are 0 directories and 250 images in '../yoga_dataset_links\\Low_Lunge_pose_or_Anjaneyasana_'.\n",
      "There are 0 directories and 39 images in '../yoga_dataset_links\\Noose_Pose_or_Pasasana_'.\n",
      "There are 0 directories and 126 images in '../yoga_dataset_links\\Peacock_Pose_or_Mayurasana_'.\n",
      "There are 0 directories and 48 images in '../yoga_dataset_links\\Pigeon_Pose_or_Kapotasana_'.\n",
      "There are 0 directories and 66 images in '../yoga_dataset_links\\Plank_Pose_or_Kumbhakasana_'.\n",
      "There are 0 directories and 295 images in '../yoga_dataset_links\\Plow_Pose_or_Halasana_'.\n",
      "There are 0 directories and 131 images in '../yoga_dataset_links\\Pose_Dedicated_to_the_Sage_Koundinya_or_Eka_Pada_Koundinyanasana_I_and_II'.\n",
      "There are 0 directories and 253 images in '../yoga_dataset_links\\Rajakapotasana'.\n",
      "There are 0 directories and 148 images in '../yoga_dataset_links\\Reclining_Hand-to-Big-Toe_Pose_or_Supta_Padangusthasana_'.\n",
      "There are 0 directories and 212 images in '../yoga_dataset_links\\Revolved_Head-to-Knee_Pose_or_Parivrtta_Janu_Sirsasana_'.\n",
      "There are 0 directories and 123 images in '../yoga_dataset_links\\Scale_Pose_or_Tolasana_'.\n",
      "There are 0 directories and 232 images in '../yoga_dataset_links\\Scorpion_pose_or_vrischikasana'.\n",
      "There are 0 directories and 329 images in '../yoga_dataset_links\\Seated_Forward_Bend_pose_or_Paschimottanasana_'.\n",
      "There are 0 directories and 92 images in '../yoga_dataset_links\\Shoulder-Pressing_Pose_or_Bhujapidasana_'.\n",
      "There are 0 directories and 70 images in '../yoga_dataset_links\\Side-Reclining_Leg_Lift_pose_or_Anantasana_'.\n",
      "There are 0 directories and 179 images in '../yoga_dataset_links\\Side_Crane_(Crow)_Pose_or_Parsva_Bakasana_'.\n",
      "There are 0 directories and 286 images in '../yoga_dataset_links\\Side_Plank_Pose_or_Vasisthasana_'.\n",
      "There are 0 directories and 663 images in '../yoga_dataset_links\\Sitting pose 1 (normal)'.\n",
      "There are 0 directories and 301 images in '../yoga_dataset_links\\Split pose'.\n",
      "There are 0 directories and 85 images in '../yoga_dataset_links\\Staff_Pose_or_Dandasana_'.\n",
      "There are 0 directories and 169 images in '../yoga_dataset_links\\Standing_big_toe_hold_pose_or_Utthita_Padangusthasana'.\n",
      "There are 0 directories and 373 images in '../yoga_dataset_links\\Standing_Forward_Bend_pose_or_Uttanasana_'.\n",
      "There are 0 directories and 133 images in '../yoga_dataset_links\\Standing_Split_pose_or_Urdhva_Prasarita_Eka_Padasana_'.\n",
      "There are 0 directories and 293 images in '../yoga_dataset_links\\Supported_Headstand_pose_or_Salamba_Sirsasana_'.\n",
      "There are 0 directories and 249 images in '../yoga_dataset_links\\Supported_Shoulderstand_pose_or_Salamba_Sarvangasana_'.\n",
      "There are 0 directories and 315 images in '../yoga_dataset_links\\Supta_Baddha_Konasana_'.\n",
      "There are 0 directories and 305 images in '../yoga_dataset_links\\Supta_Virasana_Vajrasana'.\n",
      "There are 0 directories and 159 images in '../yoga_dataset_links\\Tortoise_Pose'.\n",
      "There are 0 directories and 247 images in '../yoga_dataset_links\\Tree_Pose_or_Vrksasana_'.\n",
      "There are 0 directories and 291 images in '../yoga_dataset_links\\Upward_Bow_(Wheel)_Pose_or_Urdhva_Dhanurasana_'.\n",
      "There are 0 directories and 75 images in '../yoga_dataset_links\\Upward_Facing_Two-Foot_Staff_Pose_or_Dwi_Pada_Viparita_Dandasana_'.\n",
      "There are 0 directories and 207 images in '../yoga_dataset_links\\Upward_Plank_Pose_or_Purvottanasana_'.\n",
      "There are 0 directories and 106 images in '../yoga_dataset_links\\viparita_virabhadrasana_or_reverse_warrior_pose'.\n",
      "There are 0 directories and 322 images in '../yoga_dataset_links\\Virasana_or_Vajrasana'.\n",
      "There are 0 directories and 184 images in '../yoga_dataset_links\\Warrior_III_Pose_or_Virabhadrasana_III_'.\n",
      "There are 0 directories and 254 images in '../yoga_dataset_links\\Warrior_II_Pose_or_Virabhadrasana_II_'.\n",
      "There are 0 directories and 165 images in '../yoga_dataset_links\\Warrior_I_Pose_or_Virabhadrasana_I_'.\n",
      "There are 0 directories and 184 images in '../yoga_dataset_links\\Wide-Angle_Seated_Forward_Bend_pose_or_Upavistha_Konasana_'.\n",
      "There are 0 directories and 269 images in '../yoga_dataset_links\\Wide-Legged_Forward_Bend_pose_or_Prasarita_Padottanasana_'.\n",
      "There are 0 directories and 181 images in '../yoga_dataset_links\\Wild_Thing_pose_or_Camatkarasana_'.\n",
      "There are 0 directories and 150 images in '../yoga_dataset_links\\Wind_Relieving_pose_or_Pawanmuktasana'.\n",
      "There are 0 directories and 74 images in '../yoga_dataset_links\\Yogic_sleep_pose'.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Placing Data into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:04.188868Z",
     "start_time": "2024-11-16T06:29:03.672431Z"
    }
   },
   "source": [
    "image_dir = Path(dataset)\n",
    "\n",
    "# Get filepaths and labels\n",
    "filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))\n",
    "\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "# Concatenate filepaths and labels\n",
    "image_df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "image_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                Filepath  \\\n",
       "0      ..\\yoga_dataset_links\\Akarna_Dhanurasana\\0_15.jpg   \n",
       "1      ..\\yoga_dataset_links\\Akarna_Dhanurasana\\0_162...   \n",
       "2      ..\\yoga_dataset_links\\Akarna_Dhanurasana\\0_18.jpg   \n",
       "3      ..\\yoga_dataset_links\\Akarna_Dhanurasana\\0_305...   \n",
       "4      ..\\yoga_dataset_links\\Akarna_Dhanurasana\\0_377...   \n",
       "...                                                  ...   \n",
       "37195    ..\\yoga_dataset_links\\Yogic_sleep_pose\\2_16.jpg   \n",
       "37196    ..\\yoga_dataset_links\\Yogic_sleep_pose\\2_20.jpg   \n",
       "37197     ..\\yoga_dataset_links\\Yogic_sleep_pose\\2_8.jpg   \n",
       "37198  ..\\yoga_dataset_links\\Cobra_Pose_or_Bhujangasa...   \n",
       "37199  ..\\yoga_dataset_links\\Cobra_Pose_or_Bhujangasa...   \n",
       "\n",
       "                             Label  \n",
       "0               Akarna_Dhanurasana  \n",
       "1               Akarna_Dhanurasana  \n",
       "2               Akarna_Dhanurasana  \n",
       "3               Akarna_Dhanurasana  \n",
       "4               Akarna_Dhanurasana  \n",
       "...                            ...  \n",
       "37195             Yogic_sleep_pose  \n",
       "37196             Yogic_sleep_pose  \n",
       "37197             Yogic_sleep_pose  \n",
       "37198  Cobra_Pose_or_Bhujangasana_  \n",
       "37199  Cobra_Pose_or_Bhujangasana_  \n",
       "\n",
       "[37200 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\yoga_dataset_links\\Akarna_Dhanurasana\\0_15.jpg</td>\n",
       "      <td>Akarna_Dhanurasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\yoga_dataset_links\\Akarna_Dhanurasana\\0_162...</td>\n",
       "      <td>Akarna_Dhanurasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\yoga_dataset_links\\Akarna_Dhanurasana\\0_18.jpg</td>\n",
       "      <td>Akarna_Dhanurasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\yoga_dataset_links\\Akarna_Dhanurasana\\0_305...</td>\n",
       "      <td>Akarna_Dhanurasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\yoga_dataset_links\\Akarna_Dhanurasana\\0_377...</td>\n",
       "      <td>Akarna_Dhanurasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37195</th>\n",
       "      <td>..\\yoga_dataset_links\\Yogic_sleep_pose\\2_16.jpg</td>\n",
       "      <td>Yogic_sleep_pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37196</th>\n",
       "      <td>..\\yoga_dataset_links\\Yogic_sleep_pose\\2_20.jpg</td>\n",
       "      <td>Yogic_sleep_pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37197</th>\n",
       "      <td>..\\yoga_dataset_links\\Yogic_sleep_pose\\2_8.jpg</td>\n",
       "      <td>Yogic_sleep_pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37198</th>\n",
       "      <td>..\\yoga_dataset_links\\Cobra_Pose_or_Bhujangasa...</td>\n",
       "      <td>Cobra_Pose_or_Bhujangasana_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37199</th>\n",
       "      <td>..\\yoga_dataset_links\\Cobra_Pose_or_Bhujangasa...</td>\n",
       "      <td>Cobra_Pose_or_Bhujangasana_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37200 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Data Preprocessing\n",
    "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The data will be split into three different categories: Training, Validation and Testing. The training data will be used to train the deep learning CNN model and its parameters will be fine tuned with the validation data. Finally, the performance of the data will be evaluated using the test data(data the model has not previously seen).</p>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:21.456859Z",
     "start_time": "2024-11-16T06:29:04.189862Z"
    }
   },
   "source": [
    "# Separate in train and test data\n",
    "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=1)\n",
    "\n",
    "# 加载截断图像的容错设置\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# 检查并移除损坏的图像文件，同时更新 DataFrame\n",
    "def check_images(dataframe, filepath_col='Filepath'):\n",
    "    valid_files = []\n",
    "    for filepath in dataframe[filepath_col]:\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"File not found, skipping: {filepath}\")\n",
    "            continue\n",
    "        try:\n",
    "            # 使用 with 语句确保文件在检查后关闭\n",
    "            with Image.open(filepath) as img:\n",
    "                img.verify()  # 检查图像是否可以正常打开\n",
    "            valid_files.append(filepath)  # 记录有效文件\n",
    "        except (IOError, SyntaxError, OSError):\n",
    "            print(f\"Corrupted file detected and removed: {filepath}\")\n",
    "            try:\n",
    "                os.remove(filepath)  # 删除损坏的文件\n",
    "            except PermissionError:\n",
    "                print(f\"Could not delete {filepath} as it is being used by another process.\")\n",
    "    \n",
    "    # 更新 DataFrame，仅保留有效文件\n",
    "    return dataframe[dataframe[filepath_col].isin(valid_files)].reset_index(drop=True)\n",
    "\n",
    "# 对训练和测试数据进行检查并更新 DataFrame\n",
    "train_df = check_images(train_df)\n",
    "test_df = check_images(test_df)\n",
    "# 对训练和测试数据进行检查\n",
    "check_images(train_df)\n",
    "check_images(test_df)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anderson\\.conda\\envs\\COMP9444proj\\lib\\site-packages\\PIL\\TiffImagePlugin.py:864: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                               Filepath  \\\n",
       "0     ..\\yoga_dataset_links\\Gate_Pose_or_Parighasana...   \n",
       "1           ..\\yoga_dataset_links\\Split pose\\2_0_20.jpg   \n",
       "2     ..\\yoga_dataset_links\\Standing_Split_pose_or_U...   \n",
       "3     ..\\yoga_dataset_links\\Reclining_Hand-to-Big-To...   \n",
       "4     ..\\yoga_dataset_links\\Plow_Pose_or_Halasana_\\0...   \n",
       "...                                                 ...   \n",
       "7435  ..\\yoga_dataset_links\\Bharadvaja's_Twist_pose_...   \n",
       "7436  ..\\yoga_dataset_links\\Bow_Pose_or_Dhanurasana_...   \n",
       "7437  ..\\yoga_dataset_links\\Supta_Virasana_Vajrasana...   \n",
       "7438  ..\\yoga_dataset_links\\Firefly_Pose_or_Tittibha...   \n",
       "7439  ..\\yoga_dataset_links\\Eagle_Pose_or_Garudasana...   \n",
       "\n",
       "                                                  Label  \n",
       "0                             Gate_Pose_or_Parighasana_  \n",
       "1                                            Split pose  \n",
       "2     Standing_Split_pose_or_Urdhva_Prasarita_Eka_Pa...  \n",
       "3     Reclining_Hand-to-Big-Toe_Pose_or_Supta_Padang...  \n",
       "4                                Plow_Pose_or_Halasana_  \n",
       "...                                                 ...  \n",
       "7435       Bharadvaja's_Twist_pose_or_Bharadvajasana_I_  \n",
       "7436                           Bow_Pose_or_Dhanurasana_  \n",
       "7437                           Supta_Virasana_Vajrasana  \n",
       "7438                      Firefly_Pose_or_Tittibhasana_  \n",
       "7439                          Eagle_Pose_or_Garudasana_  \n",
       "\n",
       "[7440 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\yoga_dataset_links\\Gate_Pose_or_Parighasana...</td>\n",
       "      <td>Gate_Pose_or_Parighasana_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\yoga_dataset_links\\Split pose\\2_0_20.jpg</td>\n",
       "      <td>Split pose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\yoga_dataset_links\\Standing_Split_pose_or_U...</td>\n",
       "      <td>Standing_Split_pose_or_Urdhva_Prasarita_Eka_Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\yoga_dataset_links\\Reclining_Hand-to-Big-To...</td>\n",
       "      <td>Reclining_Hand-to-Big-Toe_Pose_or_Supta_Padang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\yoga_dataset_links\\Plow_Pose_or_Halasana_\\0...</td>\n",
       "      <td>Plow_Pose_or_Halasana_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>..\\yoga_dataset_links\\Bharadvaja's_Twist_pose_...</td>\n",
       "      <td>Bharadvaja's_Twist_pose_or_Bharadvajasana_I_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7436</th>\n",
       "      <td>..\\yoga_dataset_links\\Bow_Pose_or_Dhanurasana_...</td>\n",
       "      <td>Bow_Pose_or_Dhanurasana_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7437</th>\n",
       "      <td>..\\yoga_dataset_links\\Supta_Virasana_Vajrasana...</td>\n",
       "      <td>Supta_Virasana_Vajrasana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>..\\yoga_dataset_links\\Firefly_Pose_or_Tittibha...</td>\n",
       "      <td>Firefly_Pose_or_Tittibhasana_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>..\\yoga_dataset_links\\Eagle_Pose_or_Garudasana...</td>\n",
       "      <td>Eagle_Pose_or_Garudasana_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7440 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:21.472054Z",
     "start_time": "2024-11-16T06:29:21.457856Z"
    }
   },
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:24.262032Z",
     "start_time": "2024-11-16T06:29:21.473051Z"
    }
   },
   "source": [
    "# Split the data into three categories.\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23808 validated image filenames belonging to 82 classes.\n",
      "Found 5952 validated image filenames belonging to 82 classes.\n",
      "Found 7440 validated image filenames belonging to 82 classes.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:29.167657Z",
     "start_time": "2024-11-16T06:29:24.263029Z"
    }
   },
   "source": [
    "# Resize Layer\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(224,224),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])\n",
    "\n",
    "# Setup data augmentation\n",
    "data_augmentation = keras.Sequential([\n",
    "  preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  preprocessing.RandomRotation(0.2),\n",
    "  preprocessing.RandomZoom(0.2),\n",
    "  preprocessing.RandomHeight(0.2),\n",
    "  preprocessing.RandomWidth(0.2),                       \n",
    "], name=\"data_augmentation\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 Model Evaluation\n",
    "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The test dataset will be used to evaluate the performance of the model.One of the metrics that will be tested would be accuracy which measures the fraction of predictions the model got right. Other metrics are as follows:   </p>\n",
    "\n",
    "<h3>Precision(P):</h3> \n",
    "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The fraction of true positives (TP, correct predictions) from the total amount of relevant results, i.e., the sum of TP and false positives (FP). For multi-class classification problems, P is averaged among the classes. The following is the formula for precision.</p>\n",
    "\n",
    "<h4> <center>$P=TP/(TP+FP)$</center></h4> \n",
    "\n",
    "<h3>Recall(R): </h3> \n",
    "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The fraction of TP from the total amount of TP and false negatives (FN). For multi-class classification problems, R gets averaged among all the classes. The following is the formula for recall.</p>\n",
    "<h4><center>$R=TP/(TP+FN)$</center></h4>\n",
    "\n",
    "<h3>F1 score(F1): </h3>\n",
    "\n",
    "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The harmonic mean of precision and recall. For multi-class classification problems, F1 gets averaged among all the classes. The following is the formula for F1 score.</p>\n",
    "<h4><center>$F1=2 * (TP * FP)/(TP+FP)$</center></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:29.432072Z",
     "start_time": "2024-11-16T06:29:29.167657Z"
    }
   },
   "source": [
    "# 加载完整模型\n",
    "model = tf.keras.models.load_model(\"yoga_classification_complete_model.h5\")\n",
    "print(\"load complete\")\n",
    "\n",
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ],
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at yoga_classification_complete_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_3604\\3976277457.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# 加载完整模型\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"yoga_classification_complete_model.h5\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"load complete\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_images\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\COMP9444proj\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;31m# To get the full stack trace, call:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[1;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     71\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m             \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.conda\\envs\\COMP9444proj\\lib\\site-packages\\keras\\saving\\save.py\u001B[0m in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[0;32m    225\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_str\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    226\u001B[0m                         raise IOError(\n\u001B[1;32m--> 227\u001B[1;33m                             \u001B[1;34mf\"No file or directory found at {filepath_str}\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    228\u001B[0m                         )\n\u001B[0;32m    229\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: No file or directory found at yoga_classification_complete_model.h5"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.11 Visualizing loss curves"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:29.433069Z",
     "start_time": "2024-11-16T06:29:29.433069Z"
    }
   },
   "source": [
    "# plot_loss_curves(history)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12 Making predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:29.434065Z",
     "start_time": "2024-11-16T06:29:29.434065Z"
    }
   },
   "source": [
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "# Display the result\n",
    "print(f'The first 5 predictions: {pred[:5]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T06:29:29.435062Z",
     "start_time": "2024-11-16T06:29:29.435062Z"
    }
   },
   "source": [
    "  # Display 15 random pictures from the dataset with their labels\n",
    "random_index = np.random.randint(0, len(test_df) - 1, 15)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))\n",
    "    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:\n",
    "      color = \"green\"\n",
    "    else:\n",
    "      color = \"red\"\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\", color=color)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.13 Plotting the classification reports and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "report = classification_report(y_test, pred, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.14 Grad-Cam Visualization  - Class Activation Map"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_img_array(img_path, size=(224, 224)):\n",
    "    # 加载图像并调整大小\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    # 添加一个维度，将图像转换为批量大小\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # 创建一个模型，将输入图像映射到最后一个卷积层的激活和输出预测\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # 计算输入图像的梯度\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "    \n",
    "    # 计算相对于最后一个卷积层输出特征图的梯度\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # 获取每个特征通道的梯度平均值\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # 生成热力图\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # 归一化热力图\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # 加载原始图像\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # 将热力图缩放到 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # 使用 jet 色图来着色热力图\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # 获取 RGB 值\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # 将彩色热力图转换为图像\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # 将热力图叠加到原始图像\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "    \n",
    "    # 保存并返回叠加后的图像\n",
    "    superimposed_img.save(cam_path)\n",
    "    return cam_path\n",
    "\n",
    "# 配置模型的预处理\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n",
    "\n",
    "# 设定模型最后一个卷积层名称和图像大小\n",
    "last_conv_layer_name = \"Conv_1\"  # 更新为实际的最后卷积层名称\n",
    "img_size = (224, 224)\n",
    "\n",
    "# 移除最后一层的 softmax\n",
    "model = tf.keras.applications.MobileNetV2(weights=\"imagenet\", include_top=True)\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "# 随机选择测试集的图像并生成 Grad-CAM\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 10), subplot_kw={'xticks': [], 'yticks': []})\n",
    "random_index = random.sample(range(len(test_df)), 15)  # 假设 test_df 是你的测试集 DataFrame\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img_path = test_df.Filepath.iloc[random_index[i]]\n",
    "    img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    cam_path = save_and_display_gradcam(img_path, heatmap)\n",
    "    ax.imshow(plt.imread(cam_path))\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Using GPU:\", tf.config.list_physical_devices('GPU')[0])\n",
    "else:\n",
    "    print(\"No GPU detected, using CPU instead.\")\n",
    "\n",
    "# System libraries\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Data loading and preprocessing\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "# Changed: Aligned data generator with training settings\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=0.2,\n",
    "    rescale=1./255  # Changed: using same preprocessing as training\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1./255  # Changed: using same preprocessing as training\n",
    ")\n",
    "\n",
    "# Changed: Using directory-based data loading like in training\n",
    "dataset_path = \"../yoga_dataset_links_skeleton\"  # Update with your path\n",
    "\n",
    "# Changed: Removed DataFrame-based loading and using directory structure directly\n",
    "train_ds = data_generator.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_ds = data_generator.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(\"final/yoga_pose_model_final.h5\")  # Update with your model path\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# 在加载模型后添加以下代码\n",
    "def plot_training_curves():\n",
    "    # Loss曲线\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history['loss'], label='training_loss')\n",
    "    plt.plot(history['val_loss'], label='val_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Accuracy曲线\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history['accuracy'], label='training_accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='val_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 加载训练历史\n",
    "try:\n",
    "    history = np.load('training_history.npy', allow_pickle=True).item()\n",
    "    plot_training_curves()\n",
    "except:\n",
    "    print(\"Training history file not found\")\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "results = model.evaluate(val_ds, verbose=0)\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(val_ds)\n",
    "pred_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get class names directly from directory structure to maintain same order\n",
    "class_names = sorted(os.listdir(dataset_path))  # Changed: Getting classes in same order as training\n",
    "pred = [class_names[idx] for idx in pred_indices]\n",
    "\n",
    "print(f'The first 5 predictions: {pred[:5]}')\n",
    "\n",
    "# Get true labels\n",
    "true_labels = []\n",
    "filenames = val_ds.filenames\n",
    "for filename in filenames:\n",
    "    class_name = os.path.split(os.path.dirname(filename))[1]\n",
    "    true_labels.append(class_name)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, pred))\n",
    "\n",
    "# Display Results\n",
    "# Changed: Using directory structure to get images\n",
    "image_files = [os.path.join(dataset_path, true_labels[i], os.path.basename(filenames[i])) \n",
    "               for i in range(len(filenames))]\n",
    "random_indices = np.random.randint(0, len(image_files), 15)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img_path = image_files[random_indices[i]]\n",
    "    ax.imshow(plt.imread(img_path))\n",
    "    color = \"green\" if true_labels[random_indices[i]] == pred[random_indices[i]] else \"red\"\n",
    "    ax.set_title(f\"True: {true_labels[random_indices[i]]}\\nPredicted: {pred[random_indices[i]]}\", \n",
    "                color=color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save important metrics\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['Test Loss', 'Test Accuracy'],\n",
    "    'Value': [results[0], results[1]]\n",
    "})\n",
    "results_df.to_csv('evaluation_results.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "# Tensorflow Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Using GPU:\", tf.config.list_physical_devices('GPU')[0])\n",
    "else:\n",
    "    print(\"No GPU detected, using CPU instead.\")\n",
    "\n",
    "# System libraries\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Data loading and preprocessing\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "# Changed: Aligned data generator with training settings\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=0.2,\n",
    "    rescale=1./255  # Changed: using same preprocessing as training\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1./255  # Changed: using same preprocessing as training\n",
    ")\n",
    "\n",
    "# Changed: Using directory-based data loading like in training\n",
    "dataset_path = \"../yoga_dataset_links_skeleton\"  # Update with your path\n",
    "\n",
    "# Changed: Removed DataFrame-based loading and using directory structure directly\n",
    "train_ds = data_generator.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_ds = data_generator.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def print_classification_report(report):\n",
    "    # 打印头部\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(\" \" * 75 + \"precision    recall  f1-score   support\")\n",
    "    print()\n",
    "    \n",
    "    # 按行处理报告\n",
    "    for line in report.split('\\n'):\n",
    "        if not line.strip():  # 跳过空行\n",
    "            continue\n",
    "            \n",
    "        if line.lstrip().startswith('accuracy'):\n",
    "            name = 'accuracy'\n",
    "            line = line[8:]  # 移除 \"accuracy\"\n",
    "            print(\" \" * 75 + name + line)\n",
    "        elif line.lstrip().startswith('macro'):\n",
    "            name = 'macro avg'\n",
    "            line = line[21:]  # 移除 \"macro avg\"\n",
    "            print(\" \" * 75 + name + line)\n",
    "        elif line.lstrip().startswith('weighted'):\n",
    "            name = 'weighted avg'\n",
    "            line = line[21:]  # 移除 \"weighted avg\"\n",
    "            print(\" \" * 75 + name + line)\n",
    "        elif not line.startswith(' ' * 10):  # 跳过原始表头行\n",
    "            try:\n",
    "                # 处理常规类别行\n",
    "                items = line.split()\n",
    "                if len(items) >= 5:  # 确保行有足够的元素\n",
    "                    metrics = items[-4:]  # 最后4个元素是指标\n",
    "                    name = \" \".join(items[:-4])  # 其余的是类名\n",
    "                    metrics_str = \"{:>9} {:>9} {:>9} {:>9}\".format(*metrics)\n",
    "                    print(f\"{name:>75} {metrics_str}\")\n",
    "            except Exception as e:\n",
    "                continue  # 如果有任何处理错误，跳过该行\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(\"final/yoga_pose_model_final.h5\")  # Update with your model path\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Evaluate model\n",
    "results = model.evaluate(val_ds, verbose=0)\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(val_ds)\n",
    "pred_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get class names directly from directory structure to maintain same order\n",
    "class_names = sorted(os.listdir(dataset_path))  # Changed: Getting classes in same order as training\n",
    "pred = [class_names[idx] for idx in pred_indices]\n",
    "\n",
    "print(f'The first 5 predictions: {pred[:5]}')\n",
    "\n",
    "# Get true labels\n",
    "true_labels = []\n",
    "filenames = val_ds.filenames\n",
    "for filename in filenames:\n",
    "    class_name = os.path.split(os.path.dirname(filename))[1]\n",
    "    true_labels.append(class_name)\n",
    "\n",
    "# Generate classification report with proper formatting\n",
    "report = classification_report(true_labels, pred)\n",
    "print_classification_report(report)\n",
    "\n",
    "# Display Results\n",
    "# Changed: Using directory structure to get images\n",
    "image_files = [os.path.join(dataset_path, true_labels[i], os.path.basename(filenames[i])) \n",
    "               for i in range(len(filenames))]\n",
    "random_indices = np.random.randint(0, len(image_files), 15)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img_path = image_files[random_indices[i]]\n",
    "    ax.imshow(plt.imread(img_path))\n",
    "    color = \"green\" if true_labels[random_indices[i]] == pred[random_indices[i]] else \"red\"\n",
    "    ax.set_title(f\"True: {true_labels[random_indices[i]]}\\nPredicted: {pred[random_indices[i]]}\", \n",
    "                color=color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save important metrics\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['Test Loss', 'Test Accuracy'],\n",
    "    'Value': [results[0], results[1]]\n",
    "})\n",
    "results_df.to_csv('evaluation_results.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
