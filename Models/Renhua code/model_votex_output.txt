Version 8:09PM 12/11/2024

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split

# Updated YogaConv3d model to handle 3D voxel grids
class YogaConv3d(nn.Module):
    def __init__(self, num_classes):
        super(YogaConv3d, self).__init__()
        self.conv1 = nn.Conv3d(1, 64, kernel_size=3, padding=1)  # Assuming 1 channel for grayscale voxel grid
        self.pool = nn.MaxPool3d(2, 2)
        self.dropout1 = nn.Dropout(0.25)
        
        self.conv2 = nn.Conv3d(64, 128, kernel_size=3, padding=1)
        self.conv3 = nn.Conv3d(128, 256, kernel_size=3, padding=1)
        self.dropout2 = nn.Dropout(0.25)
        
        self.flatten = nn.Flatten()
        # Update the linear layer's input size based on the new 64x64x64 grid
        self.fc1 = nn.Linear(256 * 4 * 4 * 4, 1024)
        self.fc2 = nn.Linear(1024, num_classes)
        self.dropout3 = nn.Dropout(0.5)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.pool(x)
        x = self.dropout1(x)
        
        x = torch.relu(self.conv2(x))
        x = self.pool(x)
        x = self.dropout2(x)

        x = torch.relu(self.conv3(x))
        x = self.pool(x)
        x = self.dropout2(x)

        x = self.flatten(x)
        x = torch.relu(self.fc1(x))
        x = self.dropout3(x)
        x = self.fc2(x)
        return x


# DataLoader setup should remain similar, but your voxel grid data needs to be loaded as 3D tensors.
# Example transformation for voxel data if stored as numpy arrays:
import numpy as np
from torch.utils.data import Dataset
import os

class VoxelDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        self.samples = []  # Store file paths for each sample
        self.class_to_idx = {}  # Dictionary to store class-to-index mapping

        # Automatically generate class_to_idx based on folder names
        for idx, class_dir in enumerate(sorted(os.listdir(data_dir))):
            class_path = os.path.join(data_dir, class_dir)
            if os.path.isdir(class_path):
                self.class_to_idx[class_dir] = idx  # Assign an integer index to each class
                for file in os.listdir(class_path):
                    if file.endswith('.npy'):
                        self.samples.append((os.path.join(class_path, file), class_dir))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        file_path, class_name = self.samples[idx]
        voxel_grid = np.load(file_path)  # Load voxel grid (assume numpy format)
        voxel_grid = torch.tensor(voxel_grid, dtype=torch.float32).unsqueeze(0)  # Add channel dimension

        label = self.class_to_idx[class_name]  # Get integer label from class name
        return voxel_grid, label

# Load voxel data
input_folder = r'D:\Term 3 2024\COMP9444\COMP9444_project\Dataset\Yoga-82\yoga_dataset_links_voxel_32'
dataset = VoxelDataset(data_dir=input_folder)

# Set the train-test split ratio
train_ratio = 0.8
train_size = int(train_ratio * len(dataset))
test_size = len(dataset) - train_size

# Split the dataset into training and testing sets
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# DataLoader for training and testing sets
batch_size = 16  # Adjust batch size if necessary for memory limits
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size)

# Initialize model, loss function, and optimizer
num_classes = len(dataset.class_to_idx)
model = YogaConv3d(num_classes=num_classes)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)


# Training and Testing Loops (similar to previous implementation)
if torch.cuda.is_available():
    device = torch.device("cuda")
    print("CUDA is available. Using GPU:", torch.cuda.get_device_name(0))
else:
    device = torch.device("cpu")
    print("CUDA is not available. Using CPU.")

model.to(device)

# Training function
def train(model, train_loader, optimizer, criterion):
    model.train()
    total, correct = 0, 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)  # Move to device
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)
    
    accuracy = 100 * correct / total
    print(f"Training Accuracy: {accuracy:.6f}%")
    return accuracy

# Testing function
def test(model, test_loader, criterion):
    model.eval()
    total, correct = 0, 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)  # Move to device
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)
    
    accuracy = 100 * correct / total
    print(f"Test Accuracy: {accuracy:.6f}%")
    return accuracy

print(model)

# Training loop
epochs = 50
for epoch in range(epochs):
    print(f"Epoch {epoch + 1}/{epochs}")
    train_accuracy = train(model, train_loader, optimizer, criterion)
    if (epoch + 1) % 10 == 0:
        test_accuracy = test(model, test_loader, criterion)


PS D:\Term 3 2024\COMP9444\COMP9444_project\Dataset\Yoga-82\Renhua code>  d:; cd 'd:\Term 3 2024\COMP9444\COMP9444_project\Dataset\Yoga-82\Renhua code'; & 'c:\Users\User\AppData\Local\Programs\Python\Python311\python.exe' 'c:\Users\User\.vscode\extensions\ms-python.debugpy-2024.12.0-win32-x64\bundled\libs\debugpy\adapter/../..\debugpy\launcher' '61976' '--' 'D:\Term 3 2024\COMP9444\COMP9444_project\Dataset\Yoga-82\Renhua code\pose_model_voxel.py' 
c:\Users\User\AppData\Local\Programs\Python\Python311\Lib\site-packages\threadpoolctl.py:1214: RuntimeWarning: 
Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at
the same time. Both libraries are known to be incompatible and this
can cause random crashes or deadlocks on Linux when loaded in the
same Python program.
Using threadpoolctl may cause crashes or deadlocks. For more
information and possible workarounds, please see
    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md

  warnings.warn(msg, RuntimeWarning)
CUDA is available. Using GPU: NVIDIA GeForce GTX 1050
YogaConv3d(
  (conv1): Conv3d(1, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
  (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout1): Dropout(p=0.25, inplace=False)
  (conv2): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
  (conv3): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
  (dropout2): Dropout(p=0.25, inplace=False)
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (fc1): Linear(in_features=16384, out_features=1024, bias=True)
  (fc2): Linear(in_features=1024, out_features=82, bias=True)
  (dropout3): Dropout(p=0.5, inplace=False)
)
Epoch 1/50
Training Accuracy: 3.766392%
Epoch 2/50
Training Accuracy: 36.710887%
Epoch 3/50
Training Accuracy: 61.550778%
Epoch 4/50
Training Accuracy: 69.152181%
Epoch 5/50
Training Accuracy: 73.459896%
Epoch 6/50
Training Accuracy: 76.151266%
Epoch 7/50
Training Accuracy: 79.200976%
Epoch 8/50
Training Accuracy: 80.702958%
Epoch 9/50
Training Accuracy: 83.234218%
Epoch 10/50
Training Accuracy: 84.316865%
Test Accuracy: 74.839890%
Epoch 11/50
Training Accuracy: 85.483379%
Epoch 12/50
Training Accuracy: 86.100945%
Epoch 13/50
Training Accuracy: 87.313205%
Epoch 14/50
Training Accuracy: 88.197621%
Epoch 15/50
Training Accuracy: 88.822812%
Epoch 16/50
Training Accuracy: 89.547118%
Epoch 17/50
Training Accuracy: 89.783471%
Epoch 18/50
Training Accuracy: 90.431534%
Epoch 19/50
Training Accuracy: 90.568771%
Epoch 20/50
Training Accuracy: 91.079597%
Test Accuracy: 75.632815%
Epoch 21/50
Training Accuracy: 91.460811%
Epoch 22/50
Training Accuracy: 91.826776%
Epoch 23/50
Training Accuracy: 92.025008%
Epoch 24/50
Training Accuracy: 92.368100%
Epoch 25/50
Training Accuracy: 92.451967%
Epoch 26/50
Training Accuracy: 92.246112%
Epoch 27/50
Training Accuracy: 92.878927%
Epoch 28/50
Training Accuracy: 92.924672%
Epoch 29/50
Training Accuracy: 93.161025%
Epoch 30/50
Training Accuracy: 92.924672%
Test Accuracy: 75.510826%
Epoch 31/50
Training Accuracy: 93.206770%
Epoch 32/50
Training Accuracy: 93.626106%
Epoch 33/50
Training Accuracy: 93.870082%
Epoch 34/50
Training Accuracy: 93.389753%
Epoch 35/50
Training Accuracy: 93.359256%
Epoch 36/50
Training Accuracy: 94.068314%
Epoch 37/50
Training Accuracy: 94.205550%
Epoch 38/50
Training Accuracy: 94.365660%
Epoch 39/50
Training Accuracy: 94.175053%
Epoch 40/50
Training Accuracy: 94.579140%
Test Accuracy: 76.852699%
Epoch 41/50
Training Accuracy: 94.426654%
Epoch 42/50
Training Accuracy: 94.952729%
Epoch 43/50
Training Accuracy: 94.640134%
Epoch 44/50
Training Accuracy: 94.815493%
Epoch 45/50
Training Accuracy: 94.449527%
Epoch 46/50
Training Accuracy: 94.624886%
Epoch 47/50
Training Accuracy: 94.701128%
Epoch 48/50
Training Accuracy: 94.670631%
Epoch 49/50
Training Accuracy: 94.800244%
Epoch 50/50
Training Accuracy: 95.105215%
Test Accuracy: 75.754803%
PS D:\Term 3 2024\COMP9444\COMP9444_project\Dataset\Yoga-82\Renhua code> 